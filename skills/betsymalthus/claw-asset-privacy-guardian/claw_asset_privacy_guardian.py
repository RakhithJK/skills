#!/usr/bin/env python3
"""
Claw Asset & Privacy Guardian - èµ„äº§ä¸éšç§å®ˆæŠ¤è€…
ä¿æŠ¤æ•°å­—èµ„äº§å’Œéšç§ä¿¡æ¯ï¼Œä¸æš´éœ²ä¸»äººçš„æ•æ„Ÿä¿¡æ¯
"""

import os
import re
import json
import yaml
import hashlib
import logging
import warnings
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
import time
import sys

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ç¦ç”¨ä¸€äº›è­¦å‘Š
warnings.filterwarnings('ignore')

class RiskLevel(Enum):
    """é£é™©è¯„ä¼°ç­‰çº§"""
    CRITICAL = "critical"      # ä¸¥é‡é£é™©
    HIGH = "high"              # é«˜é£é™©  
    MEDIUM = "medium"          # ä¸­ç­‰é£é™©
    LOW = "low"                # ä½é£é™©
    INFO = "info"              # ä¿¡æ¯æ€§

class ProtectionCategory(Enum):
    """ä¿æŠ¤ç±»åˆ«"""
    SENSITIVE_INFO = "sensitive_info"       # æ•æ„Ÿä¿¡æ¯
    ACCOUNT_SECURITY = "account_security"   # è´¦å·å®‰å…¨
    PRIVACY_SETTINGS = "privacy_settings"   # éšç§è®¾ç½®
    ASSET_SECURITY = "asset_security"       # èµ„äº§å®‰å…¨
    DATA_LEAK = "data_leak"                 # æ•°æ®æ³„éœ²
    CONFIGURATION = "configuration"         # é…ç½®é—®é¢˜

@dataclass
class PrivacyFinding:
    """éšç§å’Œå®‰å…¨å‘ç°"""
    id: str                           # å”¯ä¸€æ ‡è¯†ï¼ˆåŒ¿ååŒ–ï¼‰
    category: ProtectionCategory      # é—®é¢˜ç±»åˆ«
    risk_level: RiskLevel             # é£é™©ç­‰çº§
    issue_type: str                   # é—®é¢˜ç±»å‹ï¼ˆé€šç”¨æè¿°ï¼‰
    description: str                  # é—®é¢˜æè¿°ï¼ˆåŒ¿ååŒ–ï¼‰
    location: str                     # ä½ç½®ï¼ˆåŒ¿ååŒ–å¤„ç†ï¼‰
    recommendation: str               # ä¿®å¤å»ºè®®
    detector_name: str                # æ£€æµ‹å™¨åç§°
    
    # éšç§ä¿æŠ¤å­—æ®µ
    anonymized: bool = True           # æ˜¯å¦å·²åŒ¿ååŒ–
    sensitive_info_exposed: bool = False  # æ˜¯å¦æš´éœ²æ•æ„Ÿä¿¡æ¯
    auto_fixable: bool = False        # æ˜¯å¦å¯è‡ªåŠ¨ä¿®å¤
    
    # æ—¶é—´æˆ³
    detected_at: float = field(default_factory=time.time)

@dataclass
class PrivacyReport:
    """éšç§ä¿æŠ¤æŠ¥å‘Š"""
    scan_id: str                      # æ‰«æIDï¼ˆåŒ¿åï¼‰
    total_files: int                  # æ€»æ–‡ä»¶æ•°
    scanned_files: int                # å·²æ‰«ææ–‡ä»¶æ•°
    findings: List[PrivacyFinding] = field(default_factory=list)  # æ‰€æœ‰å‘ç°
    scan_duration: float = 0.0        # æ‰«æè€—æ—¶ï¼ˆç§’ï¼‰
    
    # éšç§ä¿æŠ¤ç»Ÿè®¡
    sensitive_files_found: int = 0    # å‘ç°æ•æ„Ÿä¿¡æ¯çš„æ–‡ä»¶æ•°
    anonymized_findings: int = 0      # å·²åŒ¿ååŒ–çš„å‘ç°æ•°
    
    # é£é™©ç»Ÿè®¡
    def risk_statistics(self) -> Dict[str, int]:
        """è®¡ç®—é£é™©ç»Ÿè®¡"""
        stats = {level.value: 0 for level in RiskLevel}
        for finding in self.findings:
            stats[finding.risk_level.value] += 1
        return stats
    
    def has_critical_or_high(self) -> bool:
        """æ˜¯å¦æœ‰ä¸¥é‡æˆ–é«˜é£é™©"""
        for finding in self.findings:
            if finding.risk_level in [RiskLevel.CRITICAL, RiskLevel.HIGH]:
                return True
        return False
    
    def to_anonymous_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºåŒ¿ååŒ–å­—å…¸ï¼ˆä¸æš´éœ²æ•æ„Ÿä¿¡æ¯ï¼‰"""
        result = {
            "scan_id": self.scan_id,
            "total_files": self.total_files,
            "scanned_files": self.scanned_files,
            "findings_count": len(self.findings),
            "sensitive_files_found": self.sensitive_files_found,
            "anonymized_findings": self.anonymized_findings,
            "scan_duration": self.scan_duration,
            "risk_statistics": self.risk_statistics(),
            "has_critical_or_high": self.has_critical_or_high(),
            "findings": []
        }
        
        # åŒ¿ååŒ–æ¯ä¸ªå‘ç°
        for finding in self.findings:
            anonymous_finding = {
                "id": finding.id,
                "category": finding.category.value,
                "risk_level": finding.risk_level.value,
                "issue_type": finding.issue_type,
                "description": finding.description,
                "location": self._anonymize_location(finding.location),
                "recommendation": finding.recommendation,
                "detector_name": finding.detector_name,
                "anonymized": finding.anonymized,
                "sensitive_info_exposed": finding.sensitive_info_exposed,
                "auto_fixable": finding.auto_fixable
            }
            result["findings"].append(anonymous_finding)
        
        return result
    
    def to_anonymous_json(self) -> str:
        """è½¬æ¢ä¸ºåŒ¿ååŒ–JSON"""
        return json.dumps(self.to_anonymous_dict(), indent=2, ensure_ascii=False)
    
    def _anonymize_location(self, location: str) -> str:
        """åŒ¿ååŒ–ä½ç½®ä¿¡æ¯"""
        # ç§»é™¤ç”¨æˆ·åç­‰æ•æ„Ÿä¿¡æ¯
        location = location.replace(os.path.expanduser("~"), "~")
        
        # é€šç”¨åŒ–è·¯å¾„
        common_patterns = {
            r'/home/[^/]+/': '~/',
            r'/Users/[^/]+/': '~/',
            r'C:\\Users\\[^\\]+\\': '~\\',
        }
        
        for pattern, replacement in common_patterns.items():
            location = re.sub(pattern, replacement, location)
        
        return location

class Anonymizer:
    """åŒ¿ååŒ–å¤„ç†å™¨"""
    
    @staticmethod
    def anonymize_text(text: str, context: str = "") -> str:
        """åŒ¿ååŒ–æ–‡æœ¬ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
        if not text:
            return text
        
        # ç§»é™¤ç”µå­é‚®ä»¶
        text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '[EMAIL_REDACTED]', text)
        
        # ç§»é™¤ç”µè¯å·ç 
        text = re.sub(r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b', '[PHONE_REDACTED]', text)
        
        # ç§»é™¤èº«ä»½è¯/ç¤¾ä¿å·ç­‰
        text = re.sub(r'\b\d{3}-\d{2}-\d{4}\b', '[SSN_REDACTED]', text)
        
        # ç§»é™¤åŠ å¯†è´§å¸åœ°å€ï¼ˆéƒ¨åˆ†ï¼‰
        text = re.sub(r'\b(0x)?[A-Fa-f0-9]{40,}\b', '[CRYPTO_ADDRESS_REDACTED]', text)
        
        # ç§»é™¤APIå¯†é’¥æ¨¡å¼
        text = re.sub(r'\b(sk|pk)_[a-zA-Z0-9_\-]{20,}\b', '[API_KEY_REDACTED]', text)
        
        # ç§»é™¤JWTä»¤ç‰Œ
        text = re.sub(r'\beyJ[a-zA-Z0-9_-]+\.[a-zA-Z0-9_-]+\.[a-zA-Z0-9_-]+\b', '[JWT_TOKEN_REDACTED]', text)
        
        return text
    
    @staticmethod
    def anonymize_finding_description(description: str, original_text: str = "") -> str:
        """åŒ¿ååŒ–é—®é¢˜æè¿°"""
        # é€šç”¨é—®é¢˜æè¿°æ¨¡æ¿
        templates = {
            "api_key": "æ£€æµ‹åˆ°APIå¯†é’¥ç¡¬ç¼–ç ",
            "private_key": "æ£€æµ‹åˆ°ç§é’¥æ–‡ä»¶æˆ–å†…å®¹",
            "password": "æ£€æµ‹åˆ°å¯†ç ç¡¬ç¼–ç ",
            "email": "æ£€æµ‹åˆ°ç”µå­é‚®ä»¶åœ°å€",
            "phone": "æ£€æµ‹åˆ°ç”µè¯å·ç ",
            "crypto_wallet": "æ£€æµ‹åˆ°åŠ å¯†è´§å¸é’±åŒ…åœ°å€",
            "jwt_token": "æ£€æµ‹åˆ°JWTä»¤ç‰Œ",
            "database_url": "æ£€æµ‹åˆ°æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²",
            "aws_key": "æ£€æµ‹åˆ°AWSå‡­è¯",
        }
        
        # å°è¯•åŒ¹é…å·²çŸ¥æ¨¡å¼
        for key, template in templates.items():
            if key in description.lower():
                return template
        
        # é€šç”¨åŒ¿ååŒ–
        return "æ£€æµ‹åˆ°æ•æ„Ÿä¿¡æ¯æ³„éœ²"

class BasePrivacyDetector:
    """éšç§æ£€æµ‹å™¨åŸºç±»"""
    
    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description
        self.enabled = True
        self.anonymizer = Anonymizer()
        
    def detect(self, file_path: str, content: str) -> List[PrivacyFinding]:
        """æ£€æµ‹æ–‡ä»¶å†…å®¹ï¼Œè¿”å›åŒ¿ååŒ–çš„éšç§å‘ç°åˆ—è¡¨"""
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°detectæ–¹æ³•")
    
    def should_skip_file(self, file_path: str) -> bool:
        """æ˜¯å¦è·³è¿‡è¯¥æ–‡ä»¶"""
        skip_patterns = [
            r'node_modules/',
            r'\.git/',
            r'__pycache__/',
            r'\.pyc$',
            r'\.log$',
            r'\.tmp$',
            r'\.cache$',
        ]
        
        for pattern in skip_patterns:
            if re.search(pattern, file_path, re.IGNORECASE):
                return True
        return False
    
    def _create_finding(self, 
                       category: ProtectionCategory,
                       risk_level: RiskLevel,
                       issue_type: str,
                       description: str,
                       location: str,
                       recommendation: str,
                       original_evidence: str = "") -> PrivacyFinding:
        """åˆ›å»ºåŒ¿ååŒ–çš„å‘ç°"""
        # åŒ¿ååŒ–æè¿°
        anonymized_description = self.anonymizer.anonymize_finding_description(description, original_evidence)
        
        # æ£€æŸ¥æ˜¯å¦å¯èƒ½æš´éœ²æ•æ„Ÿä¿¡æ¯
        sensitive_exposed = self._check_sensitive_exposure(original_evidence)
        
        # ç”ŸæˆåŒ¿åID
        anonymous_id = f"priv_{hashlib.md5(f'{location}:{issue_type}'.encode()).hexdigest()[:8]}"
        
        return PrivacyFinding(
            id=anonymous_id,
            category=category,
            risk_level=risk_level,
            issue_type=issue_type,
            description=anonymized_description,
            location=location,
            recommendation=recommendation,
            detector_name=self.name,
            anonymized=True,
            sensitive_info_exposed=sensitive_exposed,
            auto_fixable=False
        )
    
    def _check_sensitive_exposure(self, evidence: str) -> bool:
        """æ£€æŸ¥è¯æ®æ˜¯å¦åŒ…å«æ•æ„Ÿä¿¡æ¯"""
        sensitive_patterns = [
            r'@[A-Za-z0-9._%+-]+\.[A-Z|a-z]{2,}',  # ç”µå­é‚®ä»¶
            r'\d{3}[-.]?\d{3}[-.]?\d{4}',           # ç”µè¯å·ç 
            r'\d{3}-\d{2}-\d{4}',                   # ç¤¾ä¿å·
            r'0x[A-Fa-f0-9]{40,}',                  # åŠ å¯†è´§å¸åœ°å€
            r'sk_[a-zA-Z0-9_\-]{20,}',              # Stripeå¯†é’¥
            r'eyJ[a-zA-Z0-9_-]+\.[a-zA-Z0-9_-]+\.[a-zA-Z0-9_-]+',  # JWT
        ]
        
        for pattern in sensitive_patterns:
            if re.search(pattern, evidence, re.IGNORECASE):
                return True
        return False

class SensitiveInfoDetector(BasePrivacyDetector):
    """æ•æ„Ÿä¿¡æ¯æ£€æµ‹å™¨"""
    
    def __init__(self):
        super().__init__("sensitive_info_detector", "æ£€æµ‹æ•æ„Ÿä¿¡æ¯æ³„éœ²")
        
        # æ•æ„Ÿä¿¡æ¯æ¨¡å¼
        self.sensitive_patterns = [
            # APIå¯†é’¥å’Œä»¤ç‰Œ
            (r'(api[_-]?key|apikey)[\s=:]+["\']?([a-zA-Z0-9_\-]{20,})["\']?', 
             ProtectionCategory.SENSITIVE_INFO, RiskLevel.CRITICAL,
             "APIå¯†é’¥ç¡¬ç¼–ç ", "ç§»é™¤ç¡¬ç¼–ç çš„APIå¯†é’¥ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å®‰å…¨å­˜å‚¨"),
            
            # ç§é’¥å’Œå¯†ç 
            (r'-----BEGIN (RSA|DSA|EC|OPENSSH) PRIVATE KEY-----',
             ProtectionCategory.SENSITIVE_INFO, RiskLevel.CRITICAL,
             "ç§é’¥æ–‡ä»¶", "å°†ç§é’¥ç§»å‡ºä»£ç åº“ï¼Œä½¿ç”¨å®‰å…¨å¯†é’¥ç®¡ç†"),
            
            # å¯†ç 
            (r'password[\s=:]+["\']?([^\s"\']{6,})["\']?',
             ProtectionCategory.SENSITIVE_INFO, RiskLevel.HIGH,
             "å¯†ç ç¡¬ç¼–ç ", "ç§»é™¤ç¡¬ç¼–ç çš„å¯†ç ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†"),
            
            # æ•°æ®åº“è¿æ¥
            (r'(mysql|postgresql|mongodb)://[^:]+:[^@]+@',
             ProtectionCategory.SENSITIVE_INFO, RiskLevel.CRITICAL,
             "æ•°æ®åº“å‡­æ®", "ç§»é™¤æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²ä¸­çš„å‡­æ®"),
            
            # AWSå‡­è¯
            (r'AWS_ACCESS_KEY_ID[\s=:]+["\']?([A-Z0-9]{20})["\']?',
             ProtectionCategory.SENSITIVE_INFO, RiskLevel.CRITICAL,
             "AWSå‡­è¯", "ç§»é™¤AWSå‡­è¯ï¼Œä½¿ç”¨IAMè§’è‰²æˆ–ç¯å¢ƒå˜é‡"),
            
            # åŠ å¯†è´§å¸é’±åŒ…
            (r'\b(0x)?[A-Fa-f0-9]{40,}\b',
             ProtectionCategory.ASSET_SECURITY, RiskLevel.CRITICAL,
             "åŠ å¯†è´§å¸åœ°å€", "ä¿æŠ¤åŠ å¯†è´§å¸åœ°å€å’Œç§é’¥"),
            
            # ä¸ªäººä¿¡æ¯
            (r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
             ProtectionCategory.PRIVACY_SETTINGS, RiskLevel.MEDIUM,
             "ç”µå­é‚®ä»¶åœ°å€", "é¿å…åœ¨ä»£ç ä¸­æš´éœ²ä¸ªäººä¿¡æ¯"),
        ]
    
    def detect(self, file_path: str, content: str) -> List[PrivacyFinding]:
        if self.should_skip_file(file_path):
            return []
        
        findings = []
        
        for pattern, category, risk_level, issue_type, recommendation in self.sensitive_patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE | re.MULTILINE)
            for match in matches:
                evidence = match.group(0)
                if len(evidence) > 100:
                    evidence = evidence[:100] + "..."
                
                finding = self._create_finding(
                    category=category,
                    risk_level=risk_level,
                    issue_type=issue_type,
                    description=f"æ£€æµ‹åˆ°{issue_type}",
                    location=file_path,
                    recommendation=recommendation,
                    original_evidence=evidence
                )
                findings.append(finding)
        
        return findings

class AccountSecurityDetector(BasePrivacyDetector):
    """è´¦å·å®‰å…¨æ£€æµ‹å™¨"""
    
    def __init__(self):
        super().__init__("account_security_detector", "æ£€æŸ¥è´¦å·å®‰å…¨é…ç½®")
    
    def detect(self, file_path: str, content: str) -> List[PrivacyFinding]:
        if self.should_skip_file(file_path):
            return []
        
        findings = []
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„è´¦å·å®‰å…¨è®¾ç½®
        if file_path.endswith('.json') or file_path.endswith('.yaml') or file_path.endswith('.yml'):
            try:
                if file_path.endswith('.json'):
                    config = json.loads(content)
                else:
                    config = yaml.safe_load(content)
                
                if isinstance(config, dict):
                    findings.extend(self._check_config_security(config, file_path))
                    
            except (json.JSONDecodeError, yaml.YAMLError):
                pass
        
        # æ£€æŸ¥ç¯å¢ƒæ–‡ä»¶
        if '.env' in file_path.lower():
            findings.extend(self._check_env_security(content, file_path))
        
        return findings
    
    def _check_config_security(self, config: Dict, file_path: str) -> List[PrivacyFinding]:
        """æ£€æŸ¥é…ç½®æ–‡ä»¶å®‰å…¨"""
        findings = []
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨åŒå› ç´ è®¤è¯
        if self._has_auth_config(config):
            mfa_enabled = config.get('mfa', config.get('two_factor', config.get('2fa', False)))
            if not mfa_enabled:
                finding = self._create_finding(
                    category=ProtectionCategory.ACCOUNT_SECURITY,
                    risk_level=RiskLevel.MEDIUM,
                    issue_type="åŒå› ç´ è®¤è¯ç¼ºå¤±",
                    description="è´¦å·é…ç½®æœªå¯ç”¨åŒå› ç´ è®¤è¯",
                    location=file_path,
                    recommendation="å¯ç”¨åŒå› ç´ è®¤è¯æé«˜è´¦å·å®‰å…¨æ€§"
                )
                findings.append(finding)
        
        # æ£€æŸ¥ä¼šè¯è¶…æ—¶è®¾ç½®
        if self._has_session_config(config):
            session_timeout = config.get('session_timeout', config.get('timeout', 0))
            if session_timeout > 86400:  # è¶…è¿‡24å°æ—¶
                finding = self._create_finding(
                    category=ProtectionCategory.ACCOUNT_SECURITY,
                    risk_level=RiskLevel.MEDIUM,
                    issue_type="ä¼šè¯è¶…æ—¶è¿‡é•¿",
                    description="ä¼šè¯è¶…æ—¶è®¾ç½®è¿‡é•¿å¯èƒ½å¸¦æ¥å®‰å…¨é£é™©",
                    location=file_path,
                    recommendation="ç¼©çŸ­ä¼šè¯è¶…æ—¶æ—¶é—´ï¼Œå»ºè®®ä¸è¶…è¿‡4å°æ—¶"
                )
                findings.append(finding)
        
        return findings
    
    def _check_env_security(self, content: str, file_path: str) -> List[PrivacyFinding]:
        """æ£€æŸ¥ç¯å¢ƒæ–‡ä»¶å®‰å…¨"""
        findings = []
        lines = content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            # æ£€æŸ¥å¯†ç å¼ºåº¦è¦æ±‚
            if 'password' in line.lower() and 'policy' not in line.lower():
                if 'min_length' not in line.lower() and 'strength' not in line.lower():
                    finding = self._create_finding(
                        category=ProtectionCategory.ACCOUNT_SECURITY,
                        risk_level=RiskLevel.LOW,
                        issue_type="å¯†ç ç­–ç•¥ç¼ºå¤±",
                        description="æœªæŒ‡å®šå¯†ç å¼ºåº¦è¦æ±‚",
                        location=f"{file_path}:{line_num}",
                        recommendation="æ·»åŠ å¯†ç å¼ºåº¦ç­–ç•¥ï¼ˆæœ€å°é•¿åº¦ã€å¤æ‚åº¦è¦æ±‚ï¼‰"
                    )
                    findings.append(finding)
        
        return findings
    
    def _has_auth_config(self, config: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰è®¤è¯é…ç½®"""
        auth_keys = ['auth', 'authentication', 'login', 'user', 'password']
        return any(key in str(config).lower() for key in auth_keys)
    
    def _has_session_config(self, config: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰ä¼šè¯é…ç½®"""
        session_keys = ['session', 'timeout', 'expire', 'cookie']
        return any(key in str(config).lower() for key in session_keys)

class AssetSecurityDetector(BasePrivacyDetector):
    """èµ„äº§å®‰å…¨æ£€æµ‹å™¨"""
    
    def __init__(self):
        super().__init__("asset_security_detector", "æ£€æŸ¥èµ„äº§å®‰å…¨")
    
    def detect(self, file_path: str, content: str) -> List[PrivacyFinding]:
        if self.should_skip_file(file_path):
            return []
        
        findings = []
        
        # æ£€æŸ¥åŠ å¯†è´§å¸é’±åŒ…ç›¸å…³æ–‡ä»¶
        if self._is_crypto_related(file_path, content):
            findings.extend(self._check_crypto_security(content, file_path))
        
        # æ£€æŸ¥è´¢åŠ¡ç›¸å…³é…ç½®
        if self._is_financial_related(file_path, content):
            findings.extend(self._check_financial_security(content, file_path))
        
        return findings
    
    def _is_crypto_related(self, file_path: str, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸åŠ å¯†è´§å¸ç›¸å…³"""
        crypto_keywords = [
            'bitcoin', 'ethereum', 'solana', 'wallet', 'crypto',
            'blockchain', 'defi', 'nft', 'token', 'coinbase'
        ]
        
        content_lower = content.lower()
        return any(keyword in content_lower for keyword in crypto_keywords)
    
    def _is_financial_related(self, file_path: str, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸è´¢åŠ¡ç›¸å…³"""
        financial_keywords = [
            'stripe', 'paypal', 'payment', 'invoice', 'transaction',
            'bank', 'account', 'finance', 'money', 'currency'
        ]
        
        content_lower = content.lower()
        return any(keyword in content_lower for keyword in financial_keywords)
    
    def _check_crypto_security(self, content: str, file_path: str) -> List[PrivacyFinding]:
        """æ£€æŸ¥åŠ å¯†è´§å¸å®‰å…¨"""
        findings = []
        
        # æ£€æŸ¥åŠ©è®°è¯æ¨¡å¼
        mnemonic_pattern = r'\b([a-z]+\s){11,23}[a-z]+\b'
        if re.search(mnemonic_pattern, content, re.IGNORECASE):
            finding = self._create_finding(
                category=ProtectionCategory.ASSET_SECURITY,
                risk_level=RiskLevel.CRITICAL,
                issue_type="åŠ å¯†è´§å¸åŠ©è®°è¯æš´éœ²",
                description="æ£€æµ‹åˆ°å¯èƒ½çš„åŠ å¯†è´§å¸åŠ©è®°è¯",
                location=file_path,
                recommendation="ç«‹å³ç§»é™¤åŠ©è®°è¯ï¼Œä½¿ç”¨ç¡¬ä»¶é’±åŒ…æˆ–å®‰å…¨å­˜å‚¨"
            )
            findings.append(finding)
        
        # æ£€æŸ¥ç§é’¥æ–‡ä»¶
        if 'PRIVATE KEY' in content and 'BEGIN' in content:
            finding = self._create_finding(
                category=ProtectionCategory.ASSET_SECURITY,
                risk_level=RiskLevel.CRITICAL,
                issue_type="åŠ å¯†è´§å¸ç§é’¥æš´éœ²",
                description="æ£€æµ‹åˆ°åŠ å¯†è´§å¸ç§é’¥",
                location=file_path,
                recommendation="ç«‹å³ç§»é™¤ç§é’¥ï¼Œä½¿ç”¨å®‰å…¨å¯†é’¥ç®¡ç†"
            )
            findings.append(finding)
        
        return findings
    
    def _check_financial_security(self, content: str, file_path: str) -> List[PrivacyFinding]:
        """æ£€æŸ¥è´¢åŠ¡å®‰å…¨"""
        findings = []
        
        # æ£€æŸ¥æ”¯ä»˜APIå¯†é’¥
        payment_patterns = [
            (r'sk_(live|test)_[a-zA-Z0-9_\-]{20,}', 'Stripeå¯†é’¥'),
            (r'PAYPAL-[A-Z0-9]{16,}', 'PayPalå¯†é’¥'),
            (r'AKIA[0-9A-Z]{16}', 'AWSæ”¯ä»˜ç›¸å…³'),
        ]
        
        for pattern, key_type in payment_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                finding = self._create_finding(
                    category=ProtectionCategory.ASSET_SECURITY,
                    risk_level=RiskLevel.CRITICAL,
                    issue_type=f"æ”¯ä»˜{key_type}æš´éœ²",
                    description=f"æ£€æµ‹åˆ°æ”¯ä»˜{key_type}",
                    location=file_path,
                    recommendation="ç«‹å³ç§»é™¤æ”¯ä»˜å¯†é’¥ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†"
                )
                findings.append(finding)
        
        return findings

class PrivacyGuardian:
    """éšç§å®ˆæŠ¤è€…ä¸»ç±»"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.detectors = self._initialize_detectors()
        self.anonymizer = Anonymizer()
        
        # æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
        self.supported_extensions = [
            '.py', '.js', '.ts', '.json', '.yaml', '.yml', 
            '.md', '.txt', '.sh', '.bash', '.env', '.toml',
            '.sql', '.html', '.css'
        ]
    
    def _initialize_detectors(self) -> List[BasePrivacyDetector]:
        """åˆå§‹åŒ–æ£€æµ‹å™¨"""
        return [
            SensitiveInfoDetector(),
            AccountSecurityDetector(),
            AssetSecurityDetector(),
        ]
    
    def scan_directory(self, directory: str) -> PrivacyReport:
        """æ‰«æç›®å½•"""
        directory = os.path.abspath(directory)
        
        logger.info(f"å¼€å§‹éšç§å®‰å…¨æ‰«æ: {directory}")
        
        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶
        all_files = self._collect_files(directory)
        logger.info(f"æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶")
        
        # åˆå§‹åŒ–æŠ¥å‘Š
        report = PrivacyReport(
            scan_id=f"scan_{hashlib.md5(f'{directory}:{time.time()}'.encode()).hexdigest()[:12]}",
            total_files=len(all_files),
            scanned_files=0,
            findings=[],
            scan_duration=0.0
        )
        
        start_time = time.time()
        
        # æ‰«ææ¯ä¸ªæ–‡ä»¶
        scanned_count = 0
        sensitive_files = 0
        
        for file_path in all_files:
            if not self._should_scan_file(file_path):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # è¿è¡Œæ‰€æœ‰æ£€æµ‹å™¨
                file_findings = []
                for detector in self.detectors:
                    if detector.enabled:
                        findings = detector.detect(file_path, content)
                        file_findings.extend(findings)
                
                if file_findings:
                    report.findings.extend(file_findings)
                    sensitive_files += 1
                    logger.debug(f"æ–‡ä»¶ {os.path.basename(file_path)} å‘ç° {len(file_findings)} ä¸ªé—®é¢˜")
                
                scanned_count += 1
                
            except Exception as e:
                logger.warning(f"æ‰«ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        report.scanned_files = scanned_count
        report.sensitive_files_found = sensitive_files
        report.anonymized_findings = len(report.findings)  # æ‰€æœ‰å‘ç°éƒ½å·²åŒ¿ååŒ–
        report.scan_duration = time.time() - start_time
        
        logger.info(f"æ‰«æå®Œæˆ: æ‰«æäº† {scanned_count} ä¸ªæ–‡ä»¶ï¼Œå‘ç° {len(report.findings)} ä¸ªé—®é¢˜")
        
        return report
    
    def _collect_files(self, directory: str) -> List[str]:
        """æ”¶é›†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
        all_files = []
        for root, dirs, files in os.walk(directory):
            # è·³è¿‡ä¸€äº›ç›®å½•
            dirs[:] = [d for d in dirs if d not in ['node_modules', '.git', '__pycache__']]
            
            for file in files:
                file_path = os.path.join(root, file)
                all_files.append(file_path)
        
        return all_files
    
    def _should_scan_file(self, file_path: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰«æè¯¥æ–‡ä»¶"""
        # æ£€æŸ¥æ‰©å±•å
        ext = os.path.splitext(file_path)[1].lower()
        if ext in self.supported_extensions:
            return True
        
        # æ£€æŸ¥ç‰¹æ®Šæ–‡ä»¶
        special_files = ['Dockerfile', 'docker-compose.yml', 'Makefile', '.env', '.env.example']
        if os.path.basename(file_path) in special_files:
            return True
        
        # æ£€æŸ¥æ²¡æœ‰æ‰©å±•åçš„æ–‡ä»¶
        if not ext:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    first_line = f.readline()
                    if first_line.startswith('#!') and ('python' in first_line or 'bash' in first_line or 'sh' in first_line):
                        return True
            except:
                pass
        
        return False
    
    def generate_report(self, report: PrivacyReport, format: str = "console") -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        if format == "json":
            return report.to_anonymous_json()
        elif format == "console":
            return self._generate_console_report(report)
        elif format == "markdown":
            return self._generate_markdown_report(report)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æŠ¥å‘Šæ ¼å¼: {format}")
    
    def _generate_console_report(self, report: PrivacyReport) -> str:
        """ç”Ÿæˆæ§åˆ¶å°æŠ¥å‘Š"""
        try:
            import colorama
            from colorama import Fore, Style
            colorama.init()
            has_color = True
        except ImportError:
            has_color = False
        
        report_lines = []
        
        if has_color:
            report_lines.append(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
            report_lines.append(f"{Fore.GREEN}Claw Asset & Privacy Guardian æŠ¥å‘Š{Style.RESET_ALL}")
            report_lines.append(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
        else:
            report_lines.append("=" * 60)
            report_lines.append("Claw Asset & Privacy Guardian æŠ¥å‘Š")
            report_lines.append("=" * 60)
        
        report_lines.append(f"æ‰«æID: {report.scan_id}")
        report_lines.append(f"æ‰«ææ—¶é—´: {report.scan_duration:.2f}ç§’")
        report_lines.append(f"æ–‡ä»¶ç»Ÿè®¡: {report.scanned_files}/{report.total_files} ä¸ªæ–‡ä»¶å·²æ‰«æ")
        report_lines.append(f"æ•æ„Ÿæ–‡ä»¶: {report.sensitive_files_found} ä¸ª")
        report_lines.append(f"åŒ¿åå‘ç°: {report.anonymized_findings} ä¸ª")
        report_lines.append("")
        
        # éšç§ä¿æŠ¤å£°æ˜
        if has_color:
            report_lines.append(f"{Fore.BLUE}ğŸ”’ éšç§ä¿æŠ¤å£°æ˜:{Style.RESET_ALL}")
        else:
            report_lines.append("ğŸ”’ éšç§ä¿æŠ¤å£°æ˜:")
        report_lines.append("  â€¢ æ‰€æœ‰æŠ¥å‘Šå‡å·²åŒ¿ååŒ–å¤„ç†")
        report_lines.append("  â€¢ ä¸åŒ…å«å…·ä½“æ•æ„Ÿä¿¡æ¯")
        report_lines.append("  â€¢ ä»…æ˜¾ç¤ºé—®é¢˜ç±»å‹å’Œå»ºè®®")
        report_lines.append("")
        
        # é£é™©ç»Ÿè®¡
        stats = report.risk_statistics()
        if has_color:
            report_lines.append(f"{Fore.YELLOW}ğŸ“Š é£é™©ç»Ÿè®¡:{Style.RESET_ALL}")
        else:
            report_lines.append("ğŸ“Š é£é™©ç»Ÿè®¡:")
        
        for level_name, count in stats.items():
            if has_color:
                color = {
                    'critical': Fore.RED,
                    'high': Fore.LIGHTRED_EX,
                    'medium': Fore.YELLOW,
                    'low': Fore.GREEN,
                    'info': Fore.BLUE
                }.get(level_name, Fore.WHITE)
                report_lines.append(f"  {color}{level_name.upper():<10}{Style.RESET_ALL}: {count}")
            else:
                report_lines.append(f"  {level_name.upper():<10}: {count}")
        
        report_lines.append("")
        
        if not report.findings:
            if has_color:
                report_lines.append(f"{Fore.GREEN}âœ… æœªå‘ç°éšç§å’Œå®‰å…¨é—®é¢˜ï¼{Style.RESET_ALL}")
            else:
                report_lines.append("âœ… æœªå‘ç°éšç§å’Œå®‰å…¨é—®é¢˜ï¼")
        else:
            # æŒ‰é£é™©ç­‰çº§åˆ†ç»„
            critical_high = [f for f in report.findings if f.risk_level in [RiskLevel.CRITICAL, RiskLevel.HIGH]]
            medium_low = [f for f in report.findings if f.risk_level in [RiskLevel.MEDIUM, RiskLevel.LOW]]
            
            if critical_high:
                if has_color:
                    report_lines.append(f"{Fore.RED}âš ï¸  ä¸¥é‡/é«˜é£é™©é—®é¢˜ ({len(critical_high)}ä¸ª):{Style.RESET_ALL}")
                else:
                    report_lines.append(f"âš ï¸  ä¸¥é‡/é«˜é£é™©é—®é¢˜ ({len(critical_high)}ä¸ª):")
                
                for finding in critical_high[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    if has_color:
                        risk_color = Fore.RED if finding.risk_level == RiskLevel.CRITICAL else Fore.LIGHTRED_EX
                        report_lines.append(f"  {risk_color}â— [{finding.category.value}] {finding.issue_type}{Style.RESET_ALL}")
                    else:
                        report_lines.append(f"  â— [{finding.category.value}] {finding.issue_type}")
                    report_lines.append(f"     æè¿°: {finding.description}")
                    report_lines.append(f"     ä½ç½®: {report._anonymize_location(finding.location)}")
                    report_lines.append(f"     å»ºè®®: {finding.recommendation}")
                    report_lines.append("")
            
            if medium_low:
                if has_color:
                    report_lines.append(f"{Fore.YELLOW}ä¸­ç­‰/ä½é£é™©é—®é¢˜ ({len(medium_low)}ä¸ª):{Style.RESET_ALL}")
                else:
                    report_lines.append(f"ä¸­ç­‰/ä½é£é™©é—®é¢˜ ({len(medium_low)}ä¸ª):")
                
                for finding in medium_low[:3]:
                    report_lines.append(f"  â— [{finding.category.value}] {finding.issue_type}")
                    report_lines.append(f"     æè¿°: {finding.description}")
                    report_lines.append("")
        
        if has_color:
            report_lines.append(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
        else:
            report_lines.append("=" * 60)
        
        return "\n".join(report_lines)
    
    def _generate_markdown_report(self, report: PrivacyReport) -> str:
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        report_lines = []
        report_lines.append("# Claw Asset & Privacy Guardian æŠ¥å‘Š")
        report_lines.append("")
        report_lines.append(f"**æ‰«æID**: `{report.scan_id}`")
        report_lines.append(f"**æ‰«ææ—¶é—´**: {report.scan_duration:.2f}ç§’")
        report_lines.append(f"**æ–‡ä»¶ç»Ÿè®¡**: {report.scanned_files}/{report.total_files} ä¸ªæ–‡ä»¶å·²æ‰«æ")
        report_lines.append(f"**æ•æ„Ÿæ–‡ä»¶**: {report.sensitive_files_found} ä¸ª")
        report_lines.append(f"**åŒ¿åå‘ç°**: {report.anonymized_findings} ä¸ª")
        report_lines.append("")
        
        # éšç§ä¿æŠ¤å£°æ˜
        report_lines.append("## ğŸ”’ éšç§ä¿æŠ¤å£°æ˜")
        report_lines.append("")
        report_lines.append("æœ¬æŠ¥å‘Šå·²è¿›è¡ŒåŒ¿ååŒ–å¤„ç†ï¼š")
        report_lines.append("- âœ… ä¸åŒ…å«å…·ä½“æ•æ„Ÿä¿¡æ¯")
        report_lines.append("- âœ… ä»…æ˜¾ç¤ºé—®é¢˜ç±»å‹å’Œå»ºè®®")
        report_lines.append("- âœ… æ‰€æœ‰åˆ†æåœ¨æœ¬åœ°å®Œæˆ")
        report_lines.append("")
        
        # é£é™©ç»Ÿè®¡
        stats = report.risk_statistics()
        report_lines.append("## ğŸ“Š é£é™©ç»Ÿè®¡")
        report_lines.append("")
        report_lines.append("| é£é™©ç­‰çº§ | æ•°é‡ |")
        report_lines.append("|----------|------|")
        for level_name, count in stats.items():
            if count > 0:
                report_lines.append(f"| {level_name.upper()} | {count} |")
        report_lines.append("")
        
        if not report.findings:
            report_lines.append("## âœ… æ‰«æç»“æœ")
            report_lines.append("")
            report_lines.append("**æœªå‘ç°éšç§å’Œå®‰å…¨é—®é¢˜ï¼**")
            report_lines.append("")
            report_lines.append("æ‚¨çš„èµ„äº§å’Œéšç§ä¿æŠ¤çŠ¶å†µè‰¯å¥½ã€‚")
        else:
            # æŒ‰é£é™©ç­‰çº§åˆ†ç»„
            critical_high = [f for f in report.findings if f.risk_level in [RiskLevel.CRITICAL, RiskLevel.HIGH]]
            medium_low = [f for f in report.findings if f.risk_level in [RiskLevel.MEDIUM, RiskLevel.LOW]]
            
            if critical_high:
                report_lines.append("## âš ï¸ ä¸¥é‡/é«˜é£é™©é—®é¢˜")
                report_lines.append("")
                for i, finding in enumerate(critical_high, 1):
                    report_lines.append(f"### {i}. [{finding.category.value.upper()}] {finding.issue_type}")
                    report_lines.append("")
                    report_lines.append(f"**é£é™©ç­‰çº§**: {finding.risk_level.value.upper()}")
                    report_lines.append("")
                    report_lines.append(f"**æè¿°**: {finding.description}")
                    report_lines.append("")
                    report_lines.append(f"**ä½ç½®**: `{report._anonymize_location(finding.location)}`")
                    report_lines.append("")
                    report_lines.append(f"**å»ºè®®**: {finding.recommendation}")
                    report_lines.append("")
            
            if medium_low:
                report_lines.append("## ä¸­ç­‰/ä½é£é™©é—®é¢˜")
                report_lines.append("")
                for i, finding in enumerate(medium_low[:10], 1):
                    report_lines.append(f"{i}. **[{finding.category.value}] {finding.issue_type}**")
                    report_lines.append(f"   - é£é™©: {finding.risk_level.value}")
                    report_lines.append(f"   - æè¿°: {finding.description}")
                    report_lines.append("")
        
        report_lines.append("---")
        report_lines.append("*æŠ¥å‘Šç”Ÿæˆå·¥å…·: Claw Asset & Privacy Guardian v0.1.0*")
        report_lines.append("*éšç§ä¿æŠ¤: æ‰€æœ‰åˆ†æåœ¨æœ¬åœ°å®Œæˆï¼Œä¸å‘é€ä»»ä½•æ•°æ®åˆ°å¤–éƒ¨*")
        
        return "\n".join(report_lines)

# å‘½ä»¤è¡Œæ¥å£
def main():
    """å‘½ä»¤è¡Œå…¥å£ç‚¹"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Claw Asset & Privacy Guardian - èµ„äº§ä¸éšç§å®ˆæŠ¤è€…')
    parser.add_argument('directory', help='è¦æ‰«æçš„ç›®å½•è·¯å¾„')
    parser.add_argument('--format', choices=['console', 'json', 'markdown'], default='console',
                       help='æŠ¥å‘Šæ ¼å¼ (default: console)')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    if args.verbose:
        logger.setLevel(logging.DEBUG)
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.directory):
        print(f"é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨: {args.directory}")
        sys.exit(1)
    
    # è¿è¡Œæ‰«æ
    guardian = PrivacyGuardian()
    report = guardian.scan_directory(args.directory)
    
    # ç”ŸæˆæŠ¥å‘Š
    report_content = guardian.generate_report(report, args.format)
    
    # è¾“å‡ºæŠ¥å‘Š
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(report_content)
        print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
    else:
        print(report_content)
    
    # é€€å‡ºç ï¼šå¦‚æœæœ‰ä¸¥é‡æˆ–é«˜é£é™©ï¼Œè¿”å›éé›¶
    if report.has_critical_or_high():
        sys.exit(1)
    else:
        sys.exit(0)

if __name__ == "__main__":
    main()